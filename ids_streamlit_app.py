# =========================================================
# IDS STREAMLIT DASHBOARD ‚Äî FINAL UPDATED VERSION
# 10 Visualizations + Reports + Fast Execution
# =========================================================

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.lib.pagesizes import A4
from io import BytesIO

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, roc_curve, precision_recall_curve
)

# ---------------- GLOBAL PLOT SETTINGS ----------------
plt.rcParams["figure.figsize"] = (4, 3)
plt.rcParams["figure.dpi"] = 120

# ---------------- PAGE CONFIG ----------------
st.set_page_config(page_title="IDS Dashboard", layout="wide")

# =========================================================
# TITLE + PROJECT OUTCOME (FRONT REPORT)
# =========================================================
st.markdown("<h1 style='text-align:center;'> Intrusion Detection System</h1>", unsafe_allow_html=True)

st.markdown("""
<div style="text-align:center; font-size:15px; max-width:900px; margin:auto; line-height:1.8;">
<b>Purpose:</b> Detect malicious network traffic using machine learning.<br>
<b>Models Used:</b> Linear SVM and XGBoost.<br>
<b>Key Result:</b> XGBoost provides better accuracy and fewer missed attacks.<br>
<b>Outcome:</b> Improved intrusion detection and network security.
</div>
""", unsafe_allow_html=True)

st.markdown("<hr>", unsafe_allow_html=True)

# =========================================================
# DATA LOADING
# =========================================================
@st.cache_data
def load_data(file):
    if file.name.endswith(".xlsx"):
        return pd.read_excel(file, engine="openpyxl").dropna().drop_duplicates()
    return pd.read_csv(file).dropna().drop_duplicates()

uploaded = st.file_uploader("Upload IDS Dataset (CSV / XLSX)", ["csv", "xlsx"])
if uploaded is None:
    st.stop()

df = load_data(uploaded)

target = df.columns[-1]
X = df.drop(columns=[target])
y = df[target].astype(int)

# =========================================================
# MODEL TRAINING
# =========================================================
@st.cache_resource
def train_models(X, y):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, stratify=y, random_state=42
    )

    scaler = StandardScaler()
    X_train_svm = scaler.fit_transform(X_train)
    X_test_svm = scaler.transform(X_test)

    svm = SVC(kernel="linear", probability=True, class_weight="balanced")
    xgb = XGBClassifier(
        n_estimators=150,
        max_depth=5,
        learning_rate=0.1,
        subsample=0.9,
        colsample_bytree=0.9,
        eval_metric="logloss"
    )

    svm.fit(X_train_svm, y_train)
    xgb.fit(X_train, y_train)

    return svm, xgb, X_test, X_test_svm, y_test

svm, xgb, X_test, X_test_svm, y_test = train_models(X, y)

# =========================================================
# PREDICTIONS & METRICS
# =========================================================
y_pred_svm = svm.predict(X_test_svm)
y_pred_xgb = xgb.predict(X_test)
y_prob_xgb = xgb.predict_proba(X_test)[:, 1]

acc_svm = accuracy_score(y_test, y_pred_svm)
acc_xgb = accuracy_score(y_test, y_pred_xgb)

cm = confusion_matrix(y_test, y_pred_xgb)

# ---------------- SAMPLE FOR FAST VISUALS ----------------
df_vis = df.sample(min(2500, len(df)), random_state=42)
y_vis = df_vis[target]

# =========================================================
# üìä VISUALIZATIONS + REPORTS
# =========================================================
st.markdown("## üìä Visual Analysis & Reports (10 Visualizations)")

# 1Ô∏è‚É£ Class Distribution
st.subheader("1Ô∏è‚É£ Class Distribution")
sns.countplot(x=y_vis)
plt.title("Normal vs Attack Distribution")
st.pyplot(plt.gcf()); plt.clf()

st.dataframe(pd.DataFrame({
    "Class": ["Normal", "Attack"],
    "Count": [(y == 0).sum(), (y == 1).sum()]
}))

# 2Ô∏è‚É£ Accuracy Comparison
st.subheader("2Ô∏è‚É£ Model Accuracy Comparison")
sns.barplot(x=["SVM", "XGBoost"], y=[acc_svm, acc_xgb])
plt.title("Accuracy Comparison")
st.pyplot(plt.gcf()); plt.clf()

st.dataframe(pd.DataFrame({
    "Model": ["SVM", "XGBoost"],
    "Accuracy": [acc_svm, acc_xgb]
}))

# 3Ô∏è‚É£ Confusion Matrix
st.subheader("3Ô∏è‚É£ Confusion Matrix")
sns.heatmap(cm, annot=True, fmt="d", cmap="Greens")
plt.title("Confusion Matrix")
st.pyplot(plt.gcf()); plt.clf()

st.dataframe(pd.DataFrame({
    "Metric": ["TN", "FP", "FN", "TP"],
    "Count": [cm[0,0], cm[0,1], cm[1,0], cm[1,1]]
}))

# 4Ô∏è‚É£ ROC Curve
st.subheader("4Ô∏è‚É£ ROC Curve")
fpr, tpr, _ = roc_curve(y_test, y_prob_xgb)
plt.plot(fpr, tpr); plt.plot([0,1],[0,1],'--')
plt.title("ROC Curve")
st.pyplot(plt.gcf()); plt.clf()

st.dataframe(pd.DataFrame({
    "Observation": ["High discrimination ability"],
    "Meaning": ["Good separation of attack vs normal"]
}))

# 5Ô∏è‚É£ Precision‚ÄìRecall Curve
st.subheader("5Ô∏è‚É£ Precision‚ÄìRecall Curve")
precision, recall, _ = precision_recall_curve(y_test, y_prob_xgb)
plt.plot(recall, precision)
plt.title("Precision‚ÄìRecall Curve")
st.pyplot(plt.gcf()); plt.clf()

st.dataframe(pd.DataFrame({
    "Metric": ["Precision", "Recall"],
    "IDS Importance": ["Reduces false alarms", "Reduces missed attacks"]
}))

# 6Ô∏è‚É£ Prediction Confidence
st.subheader("6Ô∏è‚É£ Prediction Confidence")
plt.hist(y_prob_xgb, bins=25)
plt.title("Attack Probability Distribution")
st.pyplot(plt.gcf()); plt.clf()

st.dataframe(pd.DataFrame({
    "Observation": ["High confidence predictions"],
    "Impact": ["Improves IDS reliability"]
}))

# 7Ô∏è‚É£ Error Breakdown
st.subheader("7Ô∏è‚É£ Error Breakdown")
error_df = pd.DataFrame({
    "Type": ["TN", "FP", "FN", "TP"],
    "Count": [cm[0,0], cm[0,1], cm[1,0], cm[1,1]]
})
sns.barplot(data=error_df, x="Type", y="Count")
plt.title("Error Breakdown")
st.pyplot(plt.gcf()); plt.clf()

st.dataframe(error_df)

# 8Ô∏è‚É£ Feature Importance
st.subheader("8Ô∏è‚É£ Feature Importance")
imp_df = pd.DataFrame({
    "Feature": X.columns,
    "Importance": xgb.feature_importances_
}).sort_values("Importance", ascending=False).head(8)

sns.barplot(data=imp_df, x="Importance", y="Feature")
plt.title("Top Important Features")
st.pyplot(plt.gcf()); plt.clf()

st.dataframe(imp_df)

# 9Ô∏è‚É£ Feature vs Class
st.subheader("9Ô∏è‚É£ Feature vs Class")
top_feat = imp_df.iloc[0]["Feature"]
sns.boxplot(x=y_vis, y=df_vis[top_feat])
plt.title(f"{top_feat} vs Class")
st.pyplot(plt.gcf()); plt.clf()

st.dataframe(df.groupby(target)[top_feat].describe().reset_index())

# üîü Pair Plot
st.subheader("üîü Pair Plot (Feature Relationships)")
pair_cols = df_vis.columns[:4].tolist() + [target]
pair_fig = sns.pairplot(
    df_vis[pair_cols],
    hue=target,
    corner=True,
    plot_kws={"s": 10, "alpha": 0.6}
)
pair_fig.fig.set_size_inches(6, 6)
st.pyplot(pair_fig.fig)
plt.close("all")

st.dataframe(pd.DataFrame({
    "Observation": ["Distinct clusters observed"],
    "Conclusion": ["Multiple features improve IDS accuracy"]
}))

# =========================================================
# END
# =========================================================
st.markdown("<h4 style='text-align:center;'>‚úÖ Final IDS Dashboard with Reports Ready</h4>", unsafe_allow_html=True)

def generate_ids_report_pdf():
    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4)
    styles = getSampleStyleSheet()
    elements = []

    # ---------------- TITLE ----------------
    elements.append(Paragraph("Intrusion Detection System ‚Äì Final Report", styles["Title"]))
    elements.append(Spacer(1, 12))

    # ---------------- PROJECT OUTCOME ----------------
    elements.append(Paragraph("Project Outcome & Results", styles["Heading2"]))
    elements.append(Paragraph(
        "The Intrusion Detection System successfully classifies network traffic "
        "into Normal and Attack categories. XGBoost outperforms Linear SVM by "
        "achieving higher accuracy and reducing missed attacks.",
        styles["Normal"]
    ))
    elements.append(Spacer(1, 10))

    # ---------------- DATASET SUMMARY ----------------
    elements.append(Paragraph("Dataset Summary", styles["Heading2"]))
    dataset_table = [
        ["Metric", "Value"],
        ["Total Records", df.shape[0]],
        ["Total Features", df.shape[1]],
        ["Normal Traffic", int((y == 0).sum())],
        ["Attack Traffic", int((y == 1).sum())]
    ]
    elements.append(Table(dataset_table))
    elements.append(Spacer(1, 10))

    # ---------------- MODEL PERFORMANCE ----------------
    elements.append(Paragraph("Model Performance", styles["Heading2"]))
    perf_table = [
        ["Model", "Accuracy"],
        ["Linear SVM", f"{acc_svm:.4f}"],
        ["XGBoost", f"{acc_xgb:.4f}"]
    ]
    elements.append(Table(perf_table))
    elements.append(Spacer(1, 10))

    # ---------------- CONFUSION MATRIX ----------------
    elements.append(Paragraph("Confusion Matrix (XGBoost)", styles["Heading2"]))
    cm_table = [
        ["", "Predicted Normal", "Predicted Attack"],
        ["Actual Normal", cm[0,0], cm[0,1]],
        ["Actual Attack", cm[1,0], cm[1,1]]
    ]
    elements.append(Table(cm_table))
    elements.append(Spacer(1, 10))

    # ---------------- INTERPRETATION ----------------
    elements.append(Paragraph("Interpretation", styles["Heading2"]))
    elements.append(Paragraph(
        "The low false-negative rate indicates effective attack detection. "
        "This is critical for intrusion detection systems where missing an "
        "attack can cause serious security risks.",
        styles["Normal"]
    ))
    elements.append(Spacer(1, 10))

    # ---------------- FUTURE SCOPE ----------------
    elements.append(Paragraph("Future Scope", styles["Heading2"]))
    elements.append(Paragraph(
        "- Real-time traffic monitoring<br/>"
        "- Deep learning models (LSTM, CNN)<br/>"
        "- Multi-class attack classification<br/>"
        "- Cloud-based IDS deployment",
        styles["Normal"]
    ))
    elements.append(Spacer(1, 10))

    # ---------------- LIMITATIONS ----------------
    elements.append(Paragraph("Limitations", styles["Heading2"]))
    elements.append(Paragraph(
        "- Works on offline datasets<br/>"
        "- Requires retraining for new attack patterns<br/>"
        "- Performance depends on dataset quality",
        styles["Normal"]
    ))

    doc.build(elements)
    buffer.seek(0)
    return buffer
st.markdown("## üìÑ Download Project Report")


st.download_button(
    label="üì• Download IDS Complete Report (PDF)",
    data=generate_ids_report_pdf(),
    file_name="IDS_Final_Project_Report.pdf",
    mime="application/pdf"
)
